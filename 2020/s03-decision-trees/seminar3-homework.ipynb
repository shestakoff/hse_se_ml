{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework your task will be to modify `DecisionTreeClassifier` class from your practice in class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 (0.5 point) <br/>\n",
    "\n",
    "Download Telecom Data To Analyse The Churn Data Set `telecom_churn.csv`. Read it using `pandas.read_csv()` function. To open the function description use `Shift` + `Tab` . Show the first 5 rows of the dataset using `pandas.DataFrame.head()` function.\n",
    "\n",
    "[Dataset Information](https://www.kaggle.com/spscientist/telecom-data/download):\n",
    "\n",
    "Columns:\n",
    "* state\n",
    "* account length\n",
    "* area code\n",
    "* phone number\n",
    "* international plan\n",
    "* voice mail plan\n",
    "* number vmail messages\n",
    "* total day minutes\n",
    "* total day calls\n",
    "* total day charge\n",
    "* total eve minutes\n",
    "* total eve calls\n",
    "* total eve charge\n",
    "* total night minutes\n",
    "* total night calls\n",
    "* total night charge\n",
    "* total intl minutes\n",
    "* total intl calls\n",
    "* total intl charge\n",
    "* customer service calls\n",
    "* churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which features are categorical? (0.5 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 (0.5 points) <br/>\n",
    "\n",
    "The target column for classification is `Churn`. However, it is categorical feature, so you need to encode this by `0` and `1` values (False = 0, True = 1). Implement this encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 (2 points)\n",
    "\n",
    "Encode categorical features. Use (0, 1) for binary features. Use target encoding for features with many values.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4 (2 points) <br/>\n",
    "\n",
    "Now let's look at this data. For each input feature plot two historgrams in one figure: one historgram for `0` class and the second - for `1` class, as it was done in you practice in class. How do you think, what features are the most informative? For categorical features plot frequency histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5 (0.5 points) <br/>\n",
    "\n",
    "Create matrix `X` and vector of labels `y`. Split them into train and test samples using `sklearn.model_selection.train_test_split()` function from scikit-learn library. Also, set up random state in the function `random_state=42`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6 (1 point) <br/>\n",
    "\n",
    "Fit `DecisionTreeClassifier` from you practice in class with this sample. What is `accuracy` of the classification on the test sample?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7 (3 points) <br/>\n",
    "\n",
    "Implement feature importance estimation in `DecisionTreeClassifier`. Importance of a feature $f$ is defined as follows:\n",
    "\n",
    "* Let $T(f)$ be the set of all nodes, relying on feature $f$ when making split.\n",
    "* Efficiency of split at node $t$: $\\Delta I(t)=I(t)-\\sum_{c\\in childen(t)}\\frac{n_{c}}{n_{t}}I(c)$\n",
    "* Feature importance of $f$: $\\sum_{t\\in T(f)}n_{t}\\Delta I(t)$\n",
    "\n",
    "Calculate importance of input features in your dataset. What features are the most important (informative) for the classification?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8 (3 points) <br/>\n",
    "\n",
    "Implement Reduced Error Pruning in you `DecisionTreeClassifier`. Fit the classifier similar to **Task 5** setting up `max_depth=20`. Prune this decision tree. Do you have test accuracy improvement?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
